{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 5 - Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Set default parameters for 'matplotlib' package\n",
    "# More info on tweaking default parameters: https://matplotlib.org/stable/tutorials/introductory/customizing.html\n",
    "plt.rcParams[\"figure.figsize\"] = [10,8]  # Set default figure size\n",
    "\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, you can suppress warnings using the `warnings` library. To ignore all warnings, you can use the `warnings.filterwarnings()` function with the argument `'ignore'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "#warnings.filterwarnings('ignore')                          # Suppress all warnings\n",
    "warnings.filterwarnings('ignore', module='yfinance')        # Suppress warnings from a specific library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the instruments to download. We would like to see Apple, Microsoft and the S&P500 index.\n",
    "tickers = ['AAPL', 'MSFT', '^GSPC']\n",
    "\n",
    "# We would like all available data from 01/01/2000 until 12/31/2016.\n",
    "start_date = '2010-01-01'\n",
    "end_date = '2016-12-31'\n",
    "\n",
    "# User yfinance to load the desired data. As simple as that.\n",
    "panel_data = yf.download(tickers, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panel_data.head(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the format of the datetime index:\n",
    "# NOTE: If you need to change the format of the datetime, you would have to convert the index to a string:\n",
    "# check out different options here: https://www.programiz.com/python-programming/datetime/strftime \n",
    "panel_data_formatted=panel_data.copy() # just making a copy so I don't mess up the original df\n",
    "\n",
    "panel_data_formatted.index=panel_data.index.strftime('%a, %d %b %Y')\n",
    "panel_data_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(panel_data.index))\n",
    "print(type(panel_data_formatted.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pandas, you **cannot** globally set the display format of datetime objects without converting them to strings, you can control the output format for specific output operations. \n",
    "\n",
    "You **can** change the format of the datetime but this involves actually converting the datetime object to string, which is not ideas if you rely on datetime functionality in your dataframe later on.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try selecting a subset of data on a specific date:\n",
    "panel_data[panel_data.index=='2010-01-08']\n",
    "\n",
    "# Try selecting a subset of data between specific dates:\n",
    "panel_data[(panel_data.index>='2010-01-19') & (panel_data.index<='2010-01-29')];   # what does ';' at the end of the line do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_list = {'INTC': 'Intel',\n",
    "               'MSFT': 'Microsoft',\n",
    "               'IBM': 'IBM',\n",
    "               'BHP': 'BHP',\n",
    "               'TM': 'Toyota',\n",
    "               'AAPL': 'Apple',\n",
    "               'AMZN': 'Amazon',\n",
    "               'BA': 'Boeing',\n",
    "               'QCOM': 'Qualcomm',\n",
    "               'KO': 'Coca-Cola',\n",
    "               'GOOG': 'Google',\n",
    "               'SONY': 'Sony',\n",
    "               'NFLX': 'Netflix'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(ticker_list,\n",
    "          start=dt.datetime(2021, 1, 2),\n",
    "          end=dt.datetime(2022, 2, 3)):\n",
    "    \"\"\"\n",
    "    This function reads in closing price data from Yahoo\n",
    "    for each tick in the ticker_list.\n",
    "    \"\"\"\n",
    "    \n",
    "    ticker = pd.DataFrame()\n",
    "\n",
    "    for tick in ticker_list:\n",
    "        prices = yf.download(tick, start, end)\n",
    "        closing_prices = prices['Close']\n",
    "        ticker[tick] = closing_prices\n",
    "\n",
    "    return ticker\n",
    "\n",
    "ticker = read_data(ticker_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker.head(2) \n",
    "ticker.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If instead of a dictionary, I provide a list of ticker symbols only, would my function `read_data()` still work?\n",
    "\n",
    "ticker_list2 = ['INTC',\n",
    "               'MSFT',\n",
    "               'IBM',\n",
    "               'BHP',\n",
    "               'TM',\n",
    "               'AAPL',\n",
    "               'AMZN',\n",
    "               'BA',\n",
    "               'QCOM',\n",
    "               'KO',\n",
    "               'GOOG',\n",
    "               'SONY',\n",
    "               'NFLX']\n",
    "ticker2 = read_data(ticker_list)\n",
    "ticker2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font color=DeepPink>Exercise 1</font>: \n",
    "> Using `head()` and `tail()` commands in reference to `Pandas.DataFrame` allows to view top and bottom rows. Declaring dataframe's name, e.g., `ticker`, displays the top 5 and the bottom 5 rows.<br>\n",
    "> (a) Customise it to display a specific number of rows at the top and bottom simultaneously (that is as a single output). <br>\n",
    "> (b) Customise `read_data()` function so that the dates are displayed as **yyyy-mm-dd** by defualt or the time format can be specified by the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access specific elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker.index[2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker.index[range(2,5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker.loc[ticker.index[2:5], ['BHP', 'KO']]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access only those elements that fit a condition\n",
    "\n",
    "ticker.loc[ticker.BHP<53.2, ['BHP', 'KO']]#.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a [five-point summary](https://en.wikipedia.org/wiki/Five-number_summary) statistics in a form of a table, use `.describe()` functionality (see [link](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html) for customizing its call). Later, we will see a graphical way of representing these statistics via [Box plot](https://en.wikipedia.org/wiki/Box_plot).\n",
    "\n",
    "`DataFrame.describe(percentiles=None, include=None, exclude=None, datetime_is_numeric=False)`\n",
    "\n",
    "- `percentiles` : list-like of numbers (optional). The percentiles to include in the output. All should fall between 0 and 1. The default is [.25, .5, .75], which returns the 25th, 50th, and 75th percentiles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker.describe(percentiles=[0.05, 0.25, 0.5, 0.75, 0.95], include=[np.number])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font color=DeepPink>Exercise 2</font>:<br>\n",
    "> (a) How to filter out which columns to exclude from statistical summary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker['MSFT'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker.plot(title=ticker_list,subplots=True,figsize=(12,25))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ticker.plot(title=ticker_list,subplots=False,figsize=(12,8)) # This line of code doesn't work very well. Why?\n",
    "ticker.plot(title='Prices',subplots=False,figsize=(12,8)) \n",
    "\n",
    "# Note the change in figure size above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is wrong with the picture above? How useful do you think it is for comparing stock performance?\n",
    "\n",
    "Let's try plotting returns instead to see if we can get more insight..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = ticker.pct_change()\n",
    "ret.plot(title='Returns',figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((1 + ret).cumprod() - 1).plot(title='Cumulative Returns',figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(ticker,pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdPlotReturns(x):\n",
    "    if isinstance(x,pd.DataFrame):\n",
    "        ret = ticker.pct_change()\n",
    "        ((1 + ret).cumprod() - 1).plot(title='Cumulative Returns',figsize=(12,8))\n",
    "    else:\n",
    "        print(f'The variable provided by the user is of type {type(x)} but it should be Pandas DataFrame.')   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdPlotReturns(ticker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time period is not sufficient to compare long-run performance among the stocks we selected. Let's try to extend our time window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall our previously defined function:\n",
    "ticker = read_data(ticker_list)\n",
    "ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get more data\n",
    "ticker = read_data(ticker_list, start=dt.datetime(2016, 1, 2), end=dt.datetime(2023, 2, 3))\n",
    "ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdPlotReturns(ticker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### <font color=red>Homework</font>:\n",
    "> * Modify `pdPlotReturns()` function above to allow for cumulative returns to be returned as an output in addition to displaying a plot. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load example data\n",
    "Note the possible options:\n",
    "1. Loading data from file outside of current directory.\n",
    "2. Loading data directly from the web via link to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(\"../../Data/nba.csv\") # note relative path specification\n",
    "data = pd.read_csv(\"https://media.geeksforgeeks.org/wp-content/uploads/nba.csv\")\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing null values to avoid errors  \n",
    "data.dropna(inplace = False)  # What does \"inplace=False\" mean?\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing null values to avoid errors  \n",
    "data.dropna(inplace = True)  # What does \"inplace=True\" mean?\n",
    "  \n",
    "# percentile list \n",
    "perc =[.20, .40, .60, .80] \n",
    "  \n",
    "# list of dtypes to include \n",
    "include =['object', 'float', 'int'] \n",
    "  \n",
    "# calling describe method \n",
    "desc = data.describe(percentiles = perc, include = include) \n",
    "  \n",
    "# display \n",
    "desc "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the output, statistical description of dataframe was returned with the respective passed percentiles. For the columns with strings (permitted to be included via `Object` data type), `NaN` was returned for numeric operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(percentiles = perc, include = ['float', 'int'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Name\"].describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore your data\n",
    "In the example above, we were very quick to drop missing data. Lets explore how much data did we lose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload data\n",
    "data = pd.read_csv(\"https://media.geeksforgeeks.org/wp-content/uploads/nba.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of missing entries by variable name\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now count the percentage of missing values for each column, simply by dividing the previous result by the length of the dataset (`len(df)`) and multiplying per 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()/len(data)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### <font color=red>Homework</font>: Format the output of the above line so that it\n",
    "> - displays only 2 decimal points\n",
    "> - (more challenging) also add `%` symbol at the end of each number to denote percentage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When dealing with missing values, different alternatives can be applied:\n",
    "- check the source, for example by contacting the data source to correct the missing values\n",
    "    - a problem with missing values could also occur if you are loading data from a text file in different text encoding standard or language. Letters with accent grave, apostrophes, carets, tildes may present some issues\n",
    "- drop missing values\n",
    "- replace the missing value with a value\n",
    "- leave the missing value as it is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Droping missing values** can be one of the following alternatives:\n",
    "\n",
    "- remove rows having missing values\n",
    "- remove the whole column containing missing values \n",
    "\n",
    "We can use the `dropna()` by specifying the axis to be considered. If we set `axis = 0` (by apply the function `data.dropna(axis=0)`) we drop the entire row, if we set `axis = 1` we drop the whole column (apply the function `data.dropna(axis=1)`. \n",
    "\n",
    "**<font color=blue>Important:</font>** However, removed values are not applied to the original dataframe, but only to the result. We can use the argument `inplace=True` in order to store changes in the original dataframe `data`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## <font color=red>Homework (just for fun if you have time this weekend):</font> \n",
    "The [link](https://towardsdatascience.com/how-to-extract-text-from-pdf-245482a96de7) contains reviews on some Python libraries that claim to read text directly from PDF files. Pick one or try a few, see how it perfroms. I have not yet tested this functionality in Python, but have been using it through other programming languages. \n",
    "`pdfPlumber` looks promissing and Kenny said \"`PyMuPDF` works for me. But, its syntax doesn't feel pythonic to me. `-m pip install PyMuPDF` then `import fitz` to start.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
